Article Title;Year;Authors;DOI;RQ1_Response;RQ1_Evidence;RQ2_Response;RQ2_Evidence;RQ3_Response;RQ3_Evidence;RQ4_Response;RQ4_Evidence
A Roadmap of Explainable Artificial Intelligence: Explain to Whom, When, What and How?;2024;Ziming Wang, Changwu Huang, Xin Yao;https://doi.org/10.1145/3702004;The review presents a comprehensive roadmap for XAI based on four pillars: explain to whom, when, what, and how. It does not focus on specific governance frameworks like OECD or HLEG, but rather on a systematic classification of XAI methods and stakeholder needs across the AI system lifecycle.;"""no existing work has ever considered all four pillars in a single framework and discussed interplays among the four pillars"" (Section 2)";The most emphasized governance principles are transparency, interpretability, and fairness, particularly in the context of aligning XAI methods with stakeholder needs and regulatory compliance.;"""requirements such as algorithmic fairness, non-discrimination, privacy protection, security, transparency, and interpretability"" (Section 8.2.2)";The article outlines good practices as aligning XAI methods with different stakeholder roles and stages of the AI lifecycle, and proposes a roadmap that maps explanation needs to suitable XAI techniques.;"""we can gain a comprehensive understanding of the inter-relationships among the four pillars and provide a guideline to assist stakeholders in selecting the appropriate XAI method"" (Section 6)";The article extensively discusses stakeholder roles, identifying nine types (e.g., AI experts, decision makers, users, regulators) and mapping their explanation needs to lifecycle stages and XAI methods.;"""we consider nine types of stakeholders at a fine-grained level and specify each stakeholder’s need for explanation"" (Section 3.2)"
A Systematic Literature Review on AI-Based Recommendation Systems and Their Ethical Considerations;2024;Elio Masciari, Areeba Umair, Muhammad Habib Ullah;https://doi.org/10.1109/ACCESS.2024.3451054;Not applicable;Not applicable;The most frequently addressed principles are privacy, data security, bias, and transparency. These principles are emphasized in the context of responsible AI development to ensure fair and equitable recommendations.;"""Additionally, we discuss ethical considerations such as privacy, data security, bias, and transparency, emphasizing the need for responsible AI development to ensure fair and equitable recommendations."" (Section Abstract)
""Users must be adequately informed about what data is being collected, how it will be used, and who will have access to it. [...] Techniques to detect and mitigate bias must be integrated into the development process."" (Section V)";The study discusses internal governance mechanisms such as consent mechanisms, data anonymization practices, accountability processes, and transparency in algorithm design, as essential good practices.;"""Users must be adequately informed about what data is being collected, how it will be used, and who will have access to it. Obtaining informed consent is essential to maintaining trust and transparency."" (Section V)
""Clear accountability mechanisms should be established to address any negative consequences arising from the use of recommender systems."" (Section V)";The review highlights various stakeholder roles including users (who provide data and feedback), developers (who design transparent and fair systems), and regulators (who ensure accountability and ethical standards).;"""Users should have control over their interactions with recommender systems, including the ability to modify or override recommendations and opt-out of data collection."" (Section V)
""Clear accountability mechanisms should be established [...] including having processes in place for users to report issues and for these issues to be resolved effectively."" (Section V)"
IT Governance in the Artificial Intelligence Age: Trends and Practices;2024;Kaspars ?beln?ca, Andrejs Rom?novs, Guntis Petrovskis, Agris Vindecs;https://doi.org/10.1109/ITMS64072.2024.10741935;The review discusses several governance frameworks including ITIL, COBIT, COSO, ISO 38500, and ISO 27000 as relevant for AI governance adaptation. It also proposes a layered AI-specific governance framework.;"""In this paper the following 3 frameworks and 2 standards have been used for the literature review: ITIL, COBIT, COSO, ISO 38500, ISO 27000."" (Section II)
""An example of the general structure of an AI governance framework is shown in Fig. 5."" (Section IV.B)";The review emphasizes principles like explainability, transparency, accountability, fairness, and human oversight as central to AI governance.;"""We will ensure our assumptions are clear, we will ensure algorithms are appropriately documented, decisions are explainable as needed..."" (Table I)
""Human oversight on how decisions are made and algorithms work."" (Section V)
""Accountable... Human-centric and socially beneficial..."" (Table I)";Good practices include appointing roles such as Chief AI Officer and AI Risk Officer, establishing AI-specific governance structures, and training staff for AI adoption.;"""...recommendation for companies to introduce two new roles that are dedicated to AI governance in particular."" (Section IV.A)
""The proposed aim and activities of the AI Risk Officer... of the Chief AI Officer..."" (Figures 2 and 3)";The role of stakeholders such as internal company officers (CTO, CIO, Chief AI Officer), and external influences like national AI strategies are discussed.;"""The main responsibility for AI governance in a company is assigned to roles such as the Chief Technology Officer (CTO) or Chief Information Officer (CIO)..."" (Section IV.A)
""...various national AI strategies that has become a priority for many governments..."" (Section IV.C)"
Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering;2023;Qinghua Lu, Liming Zhu, Xiwei Xu, Jon Whittle, Didar Zowghi, Aurelie Jacquet;https://arxiv.org/abs/2209.04963;The main governance frameworks discussed are operationalized as multi-level governance patterns (industry, organization, and team) rather than named frameworks like OECD or NIST.;"""We focus on patterns that practitioners can utilize in practice to ensure that the developed AI systems are responsible throughout the entire software development lifecycle."" (Section 1); ""The Responsible AI Pattern Catalogue classifies patterns into three groups: 1) governance patterns for establishing multi-level governance for responsible AI..."" (Section 1)";The principles most addressed include transparency, accountability, fairness, explainability, privacy, and safety, embedded across the pattern types.;"""The eight AI ethics principles include human, societal and environmental wellbeing, human-centred values, fairness, privacy protection and security, reliability and safety, transparency and explainability, contestability, accountability."" (Section 2.2); ""The Responsible AI Pattern Catalogue presents a comprehensive responsible AI pattern catalogue that AI system stakeholders can utilise to ensure the developed AI systems are trustworthy throughout the entire governance and engineering lifecycle..."" (Conclusion)";Organizational structures and mechanisms include ethics committees, leadership commitment, codes of ethics, risk assessment, standardized reporting, role-based accountability, and software bill of materials.;"""The management teams need to understand the values, cost and risk for adopting AI in an organization... Commitment needs to be made by the management team to build RAI culture within an organization."" (Section 3.2.1); ""An AI ethics committee is an AI governance body that is established to develop standard processes for decision-making, as well as to approve and monitor AI projects."" (Section 3.2.2); ""RAI software bill of materials keeps a list of components used to create an AI software product..."" (Section 3.2.7)";Stakeholders are categorized at industry, organization, and team levels, including regulators, developers, managers, and users. Each pattern identifies relevant stakeholder roles and interactions.;"""We identified the stakeholders for RAI governance and classified them into three groups: industry-level, organization-level, and team-level stakeholders."" (Section 3); ""Stakeholder engagement allows AI systems to better reflect their stakeholders’ needs and expectations."" (Section 3.3.4)"
Responsible AI Systems: Who are the Stakeholders?;2022;Advait Deshpande, Helen Sharp;https://doi.org/10.1145/3514094.3534187;The review does not focus on specific AI governance frameworks but discusses that over 170 guidelines exist, developed by entities like OECD, EC-HLEG, Montreal Declaration, Beijing AI Principles, Microsoft, Google, ACM, IEEE, and others.;"“Algorithm Watch [...] had identified more than 170 Artificial Intelligence (AI) guidelines in various stages of development as part of its AI Ethics Guidelines Global Inventory” (Section 1);
“guidelines such as European Commission-High-Level Expert Group (EC-HLEG) AI guidelines, OECD, Montreal declaration, and Beijing AI principles are detailed and prescriptive” (Section 4.1)";The most frequently addressed principles include transparency, accountability, fairness, explainability, trust, and responsibility. These principles are frequently mentioned as part of defining 'responsible AI'.;"“ethical AI covers moral, ethical principles of AI operation, issues of privacy, trust, transparency, responsibility, accountability, and bias” (Section 1);
“the responsible use of an AI system overlaps with the requirement for the AI system to be fair, transparent, accountable, explainable, and trustworthy” (Section 2)";Identified good practices include the creation of ethics teams, internal advisory boards, 'red teams', and structural changes in hiring practices and decision-making structures to address responsible AI impacts.;"“ethics teams specifically designated to analyse and monitor AI systems” (Section 4.2);
“internal organisational change at technology companies to ensure that an advisory board is constituted to document and monitor AI-related decision-making” (Section 4.2);
“Facebook has a ‘red team’ and technology companies such as Microsoft, Nvidia, IBM, and Google have either released or internally established frameworks” (Section 4.2)";The review discusses the role of multiple stakeholders: developers, HCI experts, researchers, users, policy makers, regulatory agencies, advocacy groups, and intergovernmental bodies. It emphasizes both direct and indirect roles in shaping responsible AI.;"“stakeholders include AI researchers, non-AI experts, policymakers, civil society, academics, impacted users, and non-users” (Section 4.1);
“stakeholders responsible for developing legal/regulatory rules for AI systems can be considered to play an indirect role” (Section 5);
“technology companies, professional bodies such as ACM, IEEE, learned societies such as the Japanese Society for Artificial Intelligence, and research institutes such as the Future of Life Institute and the Alan Turing Institute” (Section 5)"
Towards a Privacy and Security-Aware Framework for Ethical AI: Guiding the Development and Assessment of AI Systems;2024;Daria Korobenko, Anastasija Nikiforova, Rajesh Sharma;https://doi.org/10.1145/3657054.3657141;The study proposes a novel privacy- and security-aware framework for ethical AI, based on a systematic literature review of 73 studies. It highlights that only one framework (ECCOLA) partially addressed privacy and security aspects directly.;"""To sum up, our review, aimed at uncovering frameworks with a strong focus on AI privacy and security, identified only one study (ECCOLA methodology) that partially addressed our inquiry."" (Section 4.4.3)";The most frequently addressed principles are transparency, privacy, fairness, responsibility, and autonomy. Transparency and privacy are the most dominant.;"""The discourse is heavily dominated by principles of transparency, privacy, and fairness... transparency and explainability, privacy and security, fairness and justice, responsibility and accountability, and freedom and autonomy."" (Section 4.4.1)";The proposed framework identifies four key dimensions—Data, Technology, People, and Process—each with associated best practices and risk levels to guide ethical governance of AI systems.;"""The systematic literature review has identified four pivotal dimensions - Data, Technology, People, and Process... These dimensions will serve as the foundational pillars of our framework."" (Section 5)";The framework emphasizes the involvement of diverse stakeholders and human-centric considerations, particularly in the People dimension, which had the highest number of high-risk practices.;"""This underscores the importance of human-centric considerations in AI... Organizations should foster awareness of AI privacy and security concerns and nurture the practical skills necessary to address these challenges effectively."" (Section 5)"
Towards a Responsible AI Metrics Catalogue: A Collection of Metrics for AI Accountability;2024;Boming Xia, Qinghua Lu, Liming Zhu, Sung Une Lee, Yue Liu, Zhenchang Xing;https://doi.org/10.1145/3644815.3644959;The article does not present a traditional AI governance framework. Instead, it proposes a system-level metrics catalogue specifically aimed at operationalizing the principle of accountability in Responsible AI, particularly for GenAI.;"""Our catalogue delineates process metrics that underpin procedural integrity, resource metrics that provide necessary tools and frameworks, and product metrics that reflect the outputs of AI systems."" (Abstract)";The principle of accountability is central to the review, structured into three facets: Responsibility, Auditability, and Redressability. Transparency is also discussed as a foundational element that enables accountability.;"""The broader interpretation of accountability manifests in three interconnected facets: Responsibility, Auditability, and Redressability... Transparency is not an adjunct but a foundational element that empowers accountability."" (Section 2.1.1 and 2.1.2)";The review highlights good practices such as establishing RAI Oversight Committees, defining organizational AI risk tolerance, role clarity, systematic auditing, provenance tracking, and incident management protocols.;"""Such a structure is pivotal in upholding high ethical standards and responsibility in AI solutions... The establishment of an AI Governance Committee... Defining an organizational risk tolerance..."" (Section 4.1.1, 4.1.2, 4.1.3)";The article discusses the involvement of diverse stakeholders in AI governance, especially in the governance committee and auditing processes, including regulators, legal experts, technical staff, and affected users.;"""The committee should comprise experts from diverse fields like law, ethics, academia, and technology... regular collaboration with internal and external stakeholders, including regulatory bodies..."" (Section 4.1.2)"
Typology of Risks of Generative Text-to-Image Models;2023;Charlotte Bird, Eddie L. Ungless, Atoosa Kasirzadeh;http://arxiv.org/abs/2307.05543v1;The review does not explicitly structure its analysis around specific AI governance frameworks, but it discusses governance concerns via stakeholder power dynamics, regulatory instruments (e.g., EU AI Act), and socio-technical risks.;"""These tools could potentially address some socio-legal concerns associated with TTI systems... For instance, the EU AI Act can help provide a legal framework for the responsible use of TTI systems..."" (Section 3.6)";The most frequently addressed governance principles include privacy, fairness, accountability, transparency, and representational justice. Special emphasis is placed on bias, consent, copyright, and emotional/financial harm.;"""Bias investigations... tend to amplify biases inherent in the training data..."" (Section 4.1), ""This kind of intentional misuse puts a burden on developers to anticipate and prevent such behavior."" (Section 4.2), ""The generation of non-consensual sexual content represents a significant challenge..."" (Section 4.2)";The review identifies practices such as participatory design, staggered release strategies, open-source stress testing, and socio-legal regulation as organizational mechanisms to mitigate risks.;"""Participatory projects... re-defining the principles of generative AI design to be more human-centric..."" (Section 5), ""Operational solutions in the management of TTI models primarily include strategies such as the responsible release..."" (Section 5)";The role of stakeholders is extensively discussed, with categorization of developers, users, data sources, data subjects, regulators, and affected parties. Each group’s exposure to harms and influence over governance is examined.;"""We adopt the stakeholder categories of developers, users, regulators and affected parties from Langer et al. [93]..."" (Section 3), ""Affected parties include not only the consumers of misinformation/disinformation but also the primary victims of its repercussions."" (Section 4.3)"
Developing an Ethical Regulatory Framework for Artificial Intelligence: Integrating Systematic Review, Thematic Analysis, and Multidisciplinary Theories;2024;Jian Wang, Yujia Huo, Jinli Mahe, Zongyuan Ge, Zhangdaihong Liu, Wenxin Wang, Lin Zhang;https://doi.org/10.1109/ACCESS.2024.3501332;The review introduces and develops the Ethical Regulatory Framework for AI (ERF-AI), integrating insights from systematic review, thematic analysis, and multidisciplinary theories, emphasizing feedback-loop processes and structured mechanisms for regulators.;“To this end, we developed the Ethical Regulatory Framework for AI (ERF-AI) to guide regulatory bodies... The framework was developed through a systematic review, thematic analysis, and the integration of interdisciplinary concepts.” (Abstract);The most frequently addressed principles include transparency, accountability, fairness, and explainability, as well as real-time monitoring and dynamic adjustment rooted in control theory.;“The core mechanisms... serving as the procedural implementation of the strategies: real-time monitoring, prompt feedback, iterative evaluation, dynamic adjustment, and explicit reinforcement.” (Discussion - Strategy Design);Good practices include multi-role setups modeled on control systems (sensor, controller, actuator), structured feedback loops for ethical review, enforcement, and improvement, and procedures such as sandbox testing, tiered reviews, and process automation.;“Drawing an analogy with the three roles in a process control system, the ERF-AI also includes three primary roles...” and “We adopted the concept of sandbox testing from computer science to ethical regulation...” (Discussion - Role Setup and Strategy Design);The review emphasizes the critical role of stakeholders—regulators, developers, users, ethics committees, NGOs—in various feedback loops and participatory processes throughout the AI lifecycle.;“This encompasses all stakeholders, including developers, current and potential users, as well as government and non-government regulators... Stakeholders should be encouraged to participate in ethical oversight through diverse channels.” (Discussion - Role Setup and Strategy Design)
